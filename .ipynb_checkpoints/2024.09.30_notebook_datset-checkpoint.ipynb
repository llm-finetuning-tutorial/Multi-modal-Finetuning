{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets \n",
    "data = datasets.load_dataset(\"derek-thomas/ScienceQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "        num_rows: 12726\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "        num_rows: 4241\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "        num_rows: 4241\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"choices\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"answer\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PngImagePlugin.PngImageFile image mode=RGB size=750x429>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=302x232>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=302x232>,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][\"image\"][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def save_image_and_get_path(image_obj, image_id, save_dir):\n",
    "    image_path = os.path.join(save_dir, f'image_{image_id}.jpeg')\n",
    "    image_obj.save(image_path)\n",
    "    return image_path\n",
    "\n",
    "# 이미지 데이터를 저장할 경로\n",
    "save_dir = \"./image\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 데이터셋에서 이미지 객체 추출 및 저장\n",
    "for idx, example in enumerate(data[\"train\"]):\n",
    "    if idx > 101:  \n",
    "        break \n",
    "    if isinstance(example['image'], Image.Image):  # 이미지가 PIL.Image일 경우\n",
    "        image_path = save_image_and_get_path(example['image'], idx, save_dir)\n",
    "        example['image'] = image_path  # 경로를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West Virginia\n"
     ]
    }
   ],
   "source": [
    "# answer 인덱스를 choices에서 찾아와 str로 변환\n",
    "def convert_answer_to_choice(example):\n",
    "    # answer는 choices의 인덱스에 해당하므로 이를 문자열로 변환\n",
    "    example['answer_str'] = example['choices'][example['answer']]\n",
    "    return example\n",
    "\n",
    "# map 함수를 이용해 각 데이터에 대해 answer를 변환\n",
    "data['train'] = data['train'].map(convert_answer_to_choice)\n",
    "data['validation'] = data['validation'].map(convert_answer_to_choice)\n",
    "data['test'] = data['test'].map(convert_answer_to_choice)\n",
    "\n",
    "# 변환 결과 확인\n",
    "print(data['train'][0]['answer_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./image/image_0.jpeg',\n",
       " './image/image_1.jpeg',\n",
       " './image/image_2.jpeg',\n",
       " './image/image_6.jpeg',\n",
       " './image/image_7.jpeg',\n",
       " './image/image_9.jpeg',\n",
       " './image/image_10.jpeg',\n",
       " './image/image_11.jpeg',\n",
       " './image/image_13.jpeg',\n",
       " './image/image_16.jpeg']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob \n",
    "from natsort import natsorted\n",
    "image_path = natsorted(glob(\"./image/*.jpeg\"))\n",
    "image_path[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41ad2f651b341b89f688d35c4dd3e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution', 'answer_str', 'conversations'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 주어진 이미지 경로 로드\n",
    "image_dir = \"./image\"\n",
    "image_files = sorted(glob(os.path.join(image_dir, \"*.jpeg\")))\n",
    "\n",
    "# 파일명에서 인덱스만 추출하는 함수\n",
    "def get_image_index(image_path):\n",
    "    filename = os.path.basename(image_path)\n",
    "    return int(filename.split('_')[1].split('.')[0])\n",
    "\n",
    "# 인덱스와 이미지 경로를 매핑\n",
    "image_map = {get_image_index(image_path): image_path for image_path in image_files}\n",
    "\n",
    "# 주어진 데이터셋 로드\n",
    "dataset = data\n",
    "\n",
    "# conversation 포맷으로 변환하는 함수 정의\n",
    "def convert_to_conversation(example, idx):\n",
    "    # 이미지가 있는지 확인하여 없으면 질문만 포함\n",
    "    if idx in image_map:\n",
    "        conversation = [\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"<img>{image_map[idx]}</img>\\n{example['question']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"Choices: {example['choices']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"Answer: {example['answer_str']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"Solution: {example['solution']}\"\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        # 이미지가 없는 경우\n",
    "        conversation = [\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"{example['question']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"Choices: {example['choices']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"Answer: {example['answer_str']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"Solution: {example['solution']}\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    return {\"conversations\": conversation}\n",
    "\n",
    "# 변환된 데이터셋을 위해 map 함수를 사용하여 각 split에 대해 처리\n",
    "converted_train = dataset['train'].select(range(100)).map(lambda example, idx: convert_to_conversation(example, idx), with_indices=True)\n",
    "# converted_validation = dataset['validation'].select(range(100)).map(lambda example, idx: convert_to_conversation(example, idx), with_indices=True)\n",
    "# converted_test = dataset['test'].select(range(100)).map(lambda example, idx: convert_to_conversation(example, idx), with_indices=True)\n",
    "\n",
    "# 변환된 데이터셋을 새로운 DatasetDict로 묶기\n",
    "converted_dataset = datasets.DatasetDict({\n",
    "    \"train\": converted_train,\n",
    "    # \"validation\": converted_validation,\n",
    "    # \"test\": converted_test\n",
    "})\n",
    "\n",
    "# 변환된 데이터셋 출력 확인\n",
    "print(converted_dataset)\n",
    "\n",
    "# 원한다면 변환된 데이터셋을 디스크에 저장 가능\n",
    "# converted_dataset.save_to_disk('path_to_save_converted_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'user',\n",
       "  'value': '<img>./image/image_0.jpeg</img>\\nWhich of these states is farthest north?'},\n",
       " {'from': 'user',\n",
       "  'value': \"Choices: ['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma']\"},\n",
       " {'from': 'assistant', 'value': 'Answer: West Virginia'},\n",
       " {'from': 'assistant',\n",
       "  'value': 'Solution: To find the answer, look at the compass rose. Look at which way the north arrow is pointing. West Virginia is farthest north.'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_dataset[\"train\"][\"conversations\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen-vl-chat 포맷으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 formatted_conversations.json 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 데이터셋에서 conversations 부분만 추출 (converted_dataset는 이미 정의되어 있어야 합니다)\n",
    "conversations_list = converted_dataset[\"train\"][\"conversations\"]\n",
    "\n",
    "# 새로운 포맷에 맞춰 데이터를 변환\n",
    "formatted_conversations = []\n",
    "\n",
    "for idx, conversation in enumerate(conversations_list):\n",
    "    conversation_entry = {\n",
    "        \"id\": f\"identity_{idx}\",  # 각 대화에 고유 ID 부여\n",
    "        \"conversations\": conversation  # 기존 conversations 추가\n",
    "    }\n",
    "    formatted_conversations.append(conversation_entry)\n",
    "\n",
    "# 변환된 데이터를 JSON 파일로 저장\n",
    "with open('formatted_conversations.json', 'w') as f:\n",
    "    json.dump(formatted_conversations, f, indent=4)\n",
    "\n",
    "print(\"데이터가 formatted_conversations.json 파일로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
