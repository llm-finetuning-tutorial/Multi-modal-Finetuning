{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets \n",
    "data1 = datasets.load_dataset(\"derek-thomas/ScienceQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = datasets.load_dataset(\"iamjoon/KorScienceQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "         num_rows: 12726\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "         num_rows: 4241\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "         num_rows: 4241\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution', 'korean_question', 'korean_choices', 'korean_hint'],\n",
       "         num_rows: 12726\n",
       "     })\n",
       " }))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1, data2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution', 'korean_question', 'korean_choices', 'korean_hint'],\n",
       "    num_rows: 12726\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korean_columns = ['korean_question', 'korean_choices', 'korean_hint']\n",
    "korean_data = data2['train'].select_columns(korean_columns)\n",
    "\n",
    "# data1에 한국어 컬럼 추가\n",
    "new_data1 = data1['train']\n",
    "for column in korean_columns:\n",
    "    new_data1 = new_data1.add_column(column, korean_data[column])\n",
    "\n",
    "new_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['웨스트버지니아', '루이지애나', '애리조나', '오클라호마']\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data1[\"korean_choices\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['웨스트버지니아', '루이지애나', '애리조나', '오클라호마']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast \n",
    "def string_to_list(string):\n",
    "    return ast.literal_eval(string)\n",
    "\n",
    "# 데이터셋의 korean_choices 컬럼 변환\n",
    "new_korean_choices = [string_to_list(choice) for choice in new_data1['korean_choices']]\n",
    "new_data1 = new_data1.remove_columns(['korean_choices'])\n",
    "new_data1 = new_data1.add_column('korean_choices', new_korean_choices)\n",
    "new_data1[\"korean_choices\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['West Virginia', 'Louisiana', 'Arizona', 'Oklahoma']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"choices\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"answer\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.PngImagePlugin.PngImageFile image mode=RGB size=750x429>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=302x232>,\n",
       " <PIL.PngImagePlugin.PngImageFile image mode=RGB size=302x232>,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"image\"][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def save_image_and_get_path(image_obj, image_id, save_dir):\n",
    "    image_path = os.path.join(save_dir, f'image_{image_id}.jpeg')\n",
    "    image_obj.save(image_path)\n",
    "    return image_path\n",
    "\n",
    "# 이미지 데이터를 저장할 경로\n",
    "save_dir = \"./image\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 데이터셋에서 이미지 객체 추출 및 저장\n",
    "for idx, example in enumerate(data):\n",
    "    if idx > 200:  \n",
    "        break \n",
    "    if isinstance(example['image'], Image.Image):  # 이미지가 PIL.Image일 경우\n",
    "        image_path = save_image_and_get_path(example['image'], idx, save_dir)\n",
    "        example['image'] = image_path  # 경로를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웨스트버지니아\n"
     ]
    }
   ],
   "source": [
    "# answer 인덱스를 choices에서 찾아와 str로 변환\n",
    "def convert_answer_to_choice(example):\n",
    "    # answer는 choices의 인덱스에 해당하므로 이를 문자열로 변환\n",
    "    example['answer_str'] = example['korean_choices'][example['answer']]\n",
    "    return example\n",
    "\n",
    "# map 함수를 이용해 각 데이터에 대해 answer를 변환\n",
    "data = data.map(convert_answer_to_choice)\n",
    "\n",
    "# 변환 결과 확인\n",
    "print(data[0]['answer_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./image/image_0.jpeg',\n",
       " './image/image_1.jpeg',\n",
       " './image/image_2.jpeg',\n",
       " './image/image_6.jpeg',\n",
       " './image/image_7.jpeg',\n",
       " './image/image_9.jpeg',\n",
       " './image/image_10.jpeg',\n",
       " './image/image_11.jpeg',\n",
       " './image/image_13.jpeg',\n",
       " './image/image_16.jpeg']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from glob import glob \n",
    "from natsort import natsorted\n",
    "image_path = natsorted(glob(\"./image/*.jpeg\"))\n",
    "image_path[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200/200 [00:00<00:00, 3998.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution', 'korean_question', 'korean_hint', 'korean_choices', 'answer_str', 'conversations'],\n",
      "        num_rows: 200\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 주어진 이미지 경로 로드\n",
    "image_dir = \"./image\"\n",
    "image_files = sorted(glob(os.path.join(image_dir, \"*.jpeg\")))\n",
    "\n",
    "# 파일명에서 인덱스만 추출하는 함수\n",
    "def get_image_index(image_path):\n",
    "    filename = os.path.basename(image_path)\n",
    "    return int(filename.split('_')[1].split('.')[0])\n",
    "\n",
    "# 인덱스와 이미지 경로를 매핑\n",
    "image_map = {get_image_index(image_path): image_path for image_path in image_files}\n",
    "\n",
    "# 주어진 데이터셋 로드\n",
    "dataset = data\n",
    "\n",
    "# conversation 포맷으로 변환하는 함수 정의\n",
    "def convert_to_conversation(example, idx):\n",
    "    # 이미지가 있는지 확인하여 없으면 질문만 포함\n",
    "    if idx in image_map:\n",
    "        conversation = [\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"<img>{image_map[idx]}</img>\\n{example['korean_question']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"Choices: {example['korean_choices']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"Answer: {example['answer_str']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"Hint: {example['korean_hint']}\"\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        # 이미지가 없는 경우\n",
    "        conversation = [\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"{example['korean_question']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"user\",\n",
    "                \"value\": f\"Choices: {example['korean_choices']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"Answer: {example['answer_str']}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": f\"Hint: {example['korean_hint']}\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    return {\"conversations\": conversation}\n",
    "\n",
    "# 변환된 데이터셋을 위해 map 함수를 사용하여 각 split에 대해 처리\n",
    "converted_train = dataset.select(range(200)).map(lambda example, idx: convert_to_conversation(example, idx), with_indices=True)\n",
    "# converted_validation = dataset['validation'].select(range(100)).map(lambda example, idx: convert_to_conversation(example, idx), with_indices=True)\n",
    "# converted_test = dataset['test'].select(range(100)).map(lambda example, idx: convert_to_conversation(example, idx), with_indices=True)\n",
    "\n",
    "# 변환된 데이터셋을 새로운 DatasetDict로 묶기\n",
    "converted_dataset = datasets.DatasetDict({\n",
    "    \"train\": converted_train,\n",
    "    # \"validation\": converted_validation,\n",
    "    # \"test\": converted_test\n",
    "})\n",
    "\n",
    "# 변환된 데이터셋 출력 확인\n",
    "print(converted_dataset)\n",
    "\n",
    "# 원한다면 변환된 데이터셋을 디스크에 저장 가능\n",
    "# converted_dataset.save_to_disk('path_to_save_converted_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'user',\n",
       "  'value': '<img>./image/image_0.jpeg</img>\\n다음 주 중에서 가장 북쪽에 있는 곳은 어디인가요?'},\n",
       " {'from': 'user', 'value': \"Choices: ['웨스트버지니아', '루이지애나', '애리조나', '오클라호마']\"},\n",
       " {'from': 'assistant', 'value': 'Answer: 웨스트버지니아'},\n",
       " {'from': 'assistant', 'value': 'Hint: '}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_dataset[\"train\"][\"conversations\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen-vl-chat 포맷으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 데이터셋에서 conversations 부분만 추출 (converted_dataset는 이미 정의되어 있어야 합니다)\n",
    "conversations_list = converted_dataset[\"train\"][\"conversations\"]\n",
    "\n",
    "# 새로운 포맷에 맞춰 데이터를 변환\n",
    "formatted_conversations = []\n",
    "\n",
    "for idx, conversation in enumerate(conversations_list):\n",
    "    conversation_entry = {\n",
    "        \"id\": f\"identity_{idx}\",  # 각 대화에 고유 ID 부여\n",
    "        \"conversations\": conversation  # 기존 conversations 추가\n",
    "    }\n",
    "    formatted_conversations.append(conversation_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 formatted_conversations.json 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 변환된 데이터를 JSON 파일로 저장\n",
    "with open('20241016_formatted_conversations.json', 'w') as f:\n",
    "    json.dump(formatted_conversations, f, indent=4, ascii=False)\n",
    "\n",
    "print(\"데이터가 formatted_conversations.json 파일로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datadriven/anaconda3/envs/qwen_tuning/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/datadriven/anaconda3/envs/qwen_tuning/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/datadriven/anaconda3/envs/qwen_tuning/lib/python3.9/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]/home/datadriven/anaconda3/envs/qwen_tuning/lib/python3.9/site-packages/transformers/modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n",
      "/home/datadriven/anaconda3/envs/qwen_tuning/lib/python3.9/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/datadriven/anaconda3/envs/qwen_tuning/lib/python3.9/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 151860. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    \"/home/datadriven/ds.kang/Multi-modal-Finetuning/output_qwen\", # path to the output directory\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'user',\n",
       "  'value': '<img>./image/image_103.jpeg</img>\\n어떤 용액이 녹색 입자의 농도가 더 높나요?'},\n",
       " {'from': 'user', 'value': \"Choices: ['용액 A', '둘 다 아님; 농도가 동일함', '용액 B']\"}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_list[103][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datadriven/anaconda3/envs/qwen_tuning/lib/python3.9/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/datadriven/ds.kang/Multi-modal-Finetuning/output_qwen\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공통점은 화학적 변화입니다.\n"
     ]
    }
   ],
   "source": [
    "image_path = 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg'\n",
    "response, history = model.chat(tokenizer, query=f'{conversations_list[101][:2]}', history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 'assistant', 'value': 'Answer: 둘 다 화학적 변화입니다.'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_list[101][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
